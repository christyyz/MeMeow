{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "awesome_text_classifier_1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAm1NqBB-BeV"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAai5v-R90D5"
      },
      "source": [
        "DEVICE = torch.device('cpu')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDsUqN0kARmv"
      },
      "source": [
        "Mapping:\n",
        "\n",
        "\n",
        "\n",
        "1.   sad\n",
        "2.   anger\n",
        "3. fear\n",
        "4. happy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "_r6NL5cjj6GR",
        "outputId": "cd29496e-7bb1-42a7-da56-edbbf59c1e7d"
      },
      "source": [
        "df = pd.read_csv('text_ds_clean.csv')\n",
        "df"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>caption</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ive been feeling a little burdened lately wasn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17635</th>\n",
              "      <td>im having ssa examination tomorrow in the morn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17636</th>\n",
              "      <td>i constantly worry about their fight against n...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17637</th>\n",
              "      <td>i feel its important to share this info for th...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17638</th>\n",
              "      <td>i truly feel that if you are passionate enough...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17639</th>\n",
              "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17640 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 caption  sentiment\n",
              "0                                i didnt feel humiliated          0\n",
              "1      i can go from feeling so hopeless to so damned...          0\n",
              "2       im grabbing a minute to post i feel greedy wrong          1\n",
              "3                                   i am feeling grouchy          1\n",
              "4      ive been feeling a little burdened lately wasn...          0\n",
              "...                                                  ...        ...\n",
              "17635  im having ssa examination tomorrow in the morn...          0\n",
              "17636  i constantly worry about their fight against n...          3\n",
              "17637  i feel its important to share this info for th...          3\n",
              "17638  i truly feel that if you are passionate enough...          3\n",
              "17639  i feel like i just wanna buy any cute make up ...          3\n",
              "\n",
              "[17640 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j1t5NQjWyWK"
      },
      "source": [
        "Inspired by lectures from STAT 453: Intro to Deep Learning @ UW-Madison (Spring 2021) by Sebastian Raschka\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIr9VwGo-x78"
      },
      "source": [
        "TEXT = torchtext.legacy.data.Field(\n",
        "    tokenize='spacy', \n",
        "    tokenizer_language='en_core_web_sm'\n",
        ")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qj2Gl2OAg1s"
      },
      "source": [
        "LABEL = torchtext.legacy.data.LabelField(dtype=torch.long)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGlviCUSAjGT"
      },
      "source": [
        "fields = [('caption', TEXT), ('sentiment', LABEL)]\n",
        "\n",
        "dataset = torchtext.legacy.data.TabularDataset(\n",
        "    path='text_ds_clean.csv', format='csv',\n",
        "    skip_header=True, fields=fields)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z87JBkKKEJiT"
      },
      "source": [
        "## Split Dataset into Train/Validation/Test\n",
        "Split the dataset into training, validation, and test partitions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcSVTFu_BFpF"
      },
      "source": [
        "train_data, test_data = dataset.split(\n",
        "    split_ratio=[0.8, 0.2],\n",
        "    random_state=random.seed(100))\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGyg1BfUCAid"
      },
      "source": [
        "train_data, valid_data = train_data.split(\n",
        "    split_ratio=[0.85, 0.15],\n",
        "    random_state=random.seed(100))\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJNQcj51CD7F",
        "outputId": "bda5e343-58cd-4b2f-87e6-3c7c95a29a90"
      },
      "source": [
        "print(vars(train_data.examples[5]))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'caption': ['i', 'm', 'also', 'feeling', 'cranky', 'about', 'it', 'because', 'the', 'main', 'characters', 'scientist', 'brother', 'observing', 'the', 'moon', 'mentions', 'that', 'there', 'is', 'zero', 'gravity', 'there'], 'sentiment': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXMG4XTN29zx"
      },
      "source": [
        "## Build Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-TBwKWPslPa"
      },
      "source": [
        "The vocab will have only top 20000 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8uNrjdtn4A8"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=15000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhiItxwx29zy"
      },
      "source": [
        "Some sanity checks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQDrvF3F29zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a987e8-15dd-4eda-e5e5-08a7b655e48f"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('i', 21741), ('feel', 8428), ('and', 7023), ('to', 6645), ('the', 6121), ('a', 4586), ('feeling', 3843), ('that', 3800), ('of', 3659), ('my', 3145), ('in', 2515), ('it', 2290), ('m', 2147), ('like', 2099), ('so', 1892), ('for', 1738), ('have', 1720), ('was', 1716), ('me', 1698), ('but', 1645)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKUOohCS29zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352e4a80-bf8a-434f-db68-3bf892804727"
      },
      "source": [
        "print(TEXT.vocab.itos[:10]) "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'i', 'feel', 'and', 'to', 'the', 'a', 'feeling', 'that']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WMyKnrx29zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a64f693-ad04-4cd9-e44f-846d1b72b57a"
      },
      "source": [
        "print(TEXT.vocab.stoi['the']) # stoi = string-to-integer"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "241hQBWA29z0"
      },
      "source": [
        "**Class labels:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyoV5Yp029z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4854d398-0863-44b5-edd9-b46c58ca3f3a"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'3': 0, '0': 1, '1': 2, '2': 3})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQx1oQfm29z0"
      },
      "source": [
        "**Class label count:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlvYQIt-29z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b59a719-b9ec-4e68-8c54-d5cccf73b1bd"
      },
      "source": [
        "LABEL.vocab.freqs"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'0': 3956, '1': 1825, '2': 1575, '3': 4639})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjOn3EuDmMb7"
      },
      "source": [
        "train_loader, valid_loader, test_loader = \\\n",
        "    torchtext.legacy.data.BucketIterator.splits(\n",
        "        (train_data, valid_data, test_data),\n",
        "         batch_size=128,\n",
        "         sort_within_batch=False,\n",
        "         sort_key=lambda x: len(x.caption),\n",
        "         device=DEVICE\n",
        "    )"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlVUoAximPqK"
      },
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "\n",
        "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
        "                                 hidden_dim)        \n",
        "        \n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "\n",
        "    def forward(self, text):\n",
        "        # text dim: [sentence length, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        # embedded dim: [sentence length, batch size, embedding dim]\n",
        "        \n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        # output dim: [sentence length, batch size, hidden dim]\n",
        "        # hidden dim: [1, batch size, hidden dim]\n",
        "\n",
        "        hidden.squeeze_(0)\n",
        "        # hidden dim: [batch size, hidden dim]\n",
        "        \n",
        "        output = self.fc(hidden)\n",
        "        return output"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuAc9-j2mu63"
      },
      "source": [
        "torch.manual_seed(100)\n",
        "model = RNN(input_dim=len(TEXT.vocab),\n",
        "            embedding_dim=128,\n",
        "            hidden_dim=256,\n",
        "            output_dim=4 # could use 1 for binary classification\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2wc9uHLndPZ"
      },
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.float().to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YwFgRf_mwdJ"
      },
      "source": [
        "start_time = time.time()\n",
        "def train_Model(no_of_epochs):\n",
        "  for epoch in range(no_of_epochs):\n",
        "      model.train()\n",
        "      for batch_idx, batch_data in enumerate(train_loader):\n",
        "\n",
        "          text = batch_data.caption.to(DEVICE)\n",
        "          labels = batch_data.sentiment.to(DEVICE)\n",
        "\n",
        "          ### FORWARD AND BACK PROP\n",
        "          logits = model(text)\n",
        "          loss = F.cross_entropy(logits, labels)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          ### UPDATE MODEL PARAMETERS\n",
        "          optimizer.step()\n",
        "\n",
        "          ### LOGGING\n",
        "          if not batch_idx % 50:\n",
        "              print (f'Epoch: {epoch+1:03d}/{15:03d} | '\n",
        "                     f'Loss: {loss:.4f}')\n",
        "\n",
        "      with torch.set_grad_enabled(False):\n",
        "          print(f'training accuracy: '\n",
        "                f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
        "                f'\\nvalid accuracy: '\n",
        "                f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
        "\n",
        "  print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iZYsfsRZDB6",
        "outputId": "403a9259-a913-45b4-d3e0-aa62c837e6b4"
      },
      "source": [
        "train_Model(15)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001/015 | Loss: 1.4114\n",
            "Epoch: 001/015 | Loss: 1.2333\n",
            "training accuracy: 38.78%\n",
            "valid accuracy: 36.94%\n",
            "Epoch: 002/015 | Loss: 1.1817\n",
            "Epoch: 002/015 | Loss: 1.2753\n",
            "training accuracy: 38.82%\n",
            "valid accuracy: 36.32%\n",
            "Epoch: 003/015 | Loss: 1.3504\n",
            "Epoch: 003/015 | Loss: 1.2867\n",
            "training accuracy: 38.87%\n",
            "valid accuracy: 36.18%\n",
            "Epoch: 004/015 | Loss: 1.3251\n",
            "Epoch: 004/015 | Loss: 1.2286\n",
            "training accuracy: 39.02%\n",
            "valid accuracy: 34.86%\n",
            "Epoch: 005/015 | Loss: 1.2905\n",
            "Epoch: 005/015 | Loss: 1.3399\n",
            "training accuracy: 39.05%\n",
            "valid accuracy: 34.81%\n",
            "Epoch: 006/015 | Loss: 1.2435\n",
            "Epoch: 006/015 | Loss: 1.1908\n",
            "training accuracy: 50.13%\n",
            "valid accuracy: 46.53%\n",
            "Epoch: 007/015 | Loss: 0.9830\n",
            "Epoch: 007/015 | Loss: 0.8144\n",
            "training accuracy: 63.51%\n",
            "valid accuracy: 57.96%\n",
            "Epoch: 008/015 | Loss: 0.6768\n",
            "Epoch: 008/015 | Loss: 0.4585\n",
            "training accuracy: 83.56%\n",
            "valid accuracy: 78.79%\n",
            "Epoch: 009/015 | Loss: 0.2842\n",
            "Epoch: 009/015 | Loss: 0.2833\n",
            "training accuracy: 95.78%\n",
            "valid accuracy: 87.01%\n",
            "Epoch: 010/015 | Loss: 0.0875\n",
            "Epoch: 010/015 | Loss: 0.1280\n",
            "training accuracy: 98.47%\n",
            "valid accuracy: 92.16%\n",
            "Epoch: 011/015 | Loss: 0.0150\n",
            "Epoch: 011/015 | Loss: 0.0383\n",
            "training accuracy: 98.97%\n",
            "valid accuracy: 92.58%\n",
            "Epoch: 012/015 | Loss: 0.0120\n",
            "Epoch: 012/015 | Loss: 0.0211\n",
            "training accuracy: 99.62%\n",
            "valid accuracy: 92.73%\n",
            "Epoch: 013/015 | Loss: 0.0030\n",
            "Epoch: 013/015 | Loss: 0.0091\n",
            "training accuracy: 99.67%\n",
            "valid accuracy: 92.82%\n",
            "Epoch: 014/015 | Loss: 0.0091\n",
            "Epoch: 014/015 | Loss: 0.0015\n",
            "training accuracy: 99.54%\n",
            "valid accuracy: 93.48%\n",
            "Epoch: 015/015 | Loss: 0.0032\n",
            "Epoch: 015/015 | Loss: 0.0040\n",
            "training accuracy: 99.71%\n",
            "valid accuracy: 92.44%\n",
            "Test accuracy: 90.96%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ07km6WrbsP"
      },
      "source": [
        "- Happy : 0\n",
        "- Sad   : 1\n",
        "- Anger : 2\n",
        "- Fear  : 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVzYTr58nFN5",
        "outputId": "e75abc91-34c3-44e0-c873-63cc2ff91fcd"
      },
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = model(tensor)\n",
        "    return prediction, tensor.shape\n",
        "\n",
        "predict_sentiment(model, \"count not the troubles but the joys\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.4724, -0.2632, -0.0916, -0.5106]], grad_fn=<AddmmBackward>),\n",
              " torch.Size([7, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmjQbr9azkKt"
      },
      "source": [
        "### Optimizing our model for mobile and downloading it:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7y6c3MbPYIg"
      },
      "source": [
        "cpu_model = model.cpu()\n",
        "torchscript_model = torch.jit.script(cpu_model)\n",
        "torch.jit.save(torchscript_model, \"MemeSentiment_model_V4.pt\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esUE1BHlcvnh"
      },
      "source": [
        "### Downloading the vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyWIIXm2czks"
      },
      "source": [
        "def save_vocab(vocab, path):\n",
        "    with open(path, 'w+') as f:\n",
        "        for token, index in vocab.stoi.items():\n",
        "            f.write(f'{token}' +',' + f'{index} \\n')"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4vhjNFTc1lj"
      },
      "source": [
        "save_vocab(TEXT.vocab,'vocab.txt')"
      ],
      "execution_count": 87,
      "outputs": []
    }
  ]
}